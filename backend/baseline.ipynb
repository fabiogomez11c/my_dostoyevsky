{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_files_from_folder, open_txt\n",
    "from src.model import BigramLanguageModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTES FROM THE UNDERGROUND[*]\n",
      "A NOVEL\n",
      "\n",
      "\n",
      "* The author of the diary and the diary itself are, of course,\n",
      "imaginary. Nevertheless it is clear that such persons as the writer of\n",
      "these notes not only may, but positively must, exist in our society,\n",
      "when we consider the circumstances in the midst of which our society is\n",
      "formed. I have tried to expose to the view of the public more\n",
      "distinctly than is commonly done, one of the characters of the recent\n",
      "past. He is one of the representatives of a generatio\n"
     ]
    }
   ],
   "source": [
    "books = get_files_from_folder(\"books\")\n",
    "books_string = [open_txt(f\"books/{i}\") for i in books]\n",
    "print(books_string[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All books have a lenght of: 7113352\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'Æ', 'É', 'à', 'â', 'ä', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ô', 'ö', 'ü', 'Œ', 'œ', '‐', '—', '‘', '’', '“', '”']\n",
      "The vocabulary has a lenght of: 104\n"
     ]
    }
   ],
   "source": [
    "all_books = \"\\n\".join(books_string)\n",
    "print(f\"All books have a lenght of: {len(all_books)}\")\n",
    "\n",
    "vocab = sorted(set(all_books))\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)\n",
    "print(f\"The vocabulary has a lenght of: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 67, 71, 72, 67, 77, 57, 74, 71, 63, 77]\n",
      "Dostoyevsky\n"
     ]
    }
   ],
   "source": [
    "stoi = {c: i for i, c in enumerate(vocab)}\n",
    "itos = {i: c for i, c in enumerate(vocab)}\n",
    "encode = lambda x: [stoi[c] for c in x]\n",
    "decode = lambda x: \"\".join([itos[c] for c in x])\n",
    "\n",
    "print(encode(\"Dostoyevsky\"))\n",
    "print(decode(encode(\"Dostoyevsky\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7113352]) torch.int64\n",
      "tensor([37, 38, 43, 28, 42,  1, 29, 41, 38, 36])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(all_books), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.9)\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[70,  1, 72, 60, 61, 70, 72, 77],\n",
      "        [57,  1, 72, 67,  1, 58, 53, 55],\n",
      "        [57, 10,  1, 46, 60, 53, 72,  1],\n",
      "        [72,  1, 72, 67,  1, 65, 57,  1]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1, 72, 60, 61, 70, 72, 77,  1],\n",
      "        [ 1, 72, 67,  1, 58, 53, 55, 57],\n",
      "        [10,  1, 46, 60, 53, 72,  1, 65],\n",
      "        [ 1, 72, 67,  1, 65, 57,  1, 53]])\n",
      "----\n",
      "when input is [70] the target: 1\n",
      "when input is [70, 1] the target: 72\n",
      "when input is [70, 1, 72] the target: 60\n",
      "when input is [70, 1, 72, 60] the target: 61\n",
      "when input is [70, 1, 72, 60, 61] the target: 70\n",
      "when input is [70, 1, 72, 60, 61, 70] the target: 72\n",
      "when input is [70, 1, 72, 60, 61, 70, 72] the target: 77\n",
      "when input is [70, 1, 72, 60, 61, 70, 72, 77] the target: 1\n",
      "when input is [57] the target: 1\n",
      "when input is [57, 1] the target: 72\n",
      "when input is [57, 1, 72] the target: 67\n",
      "when input is [57, 1, 72, 67] the target: 1\n",
      "when input is [57, 1, 72, 67, 1] the target: 58\n",
      "when input is [57, 1, 72, 67, 1, 58] the target: 53\n",
      "when input is [57, 1, 72, 67, 1, 58, 53] the target: 55\n",
      "when input is [57, 1, 72, 67, 1, 58, 53, 55] the target: 57\n",
      "when input is [57] the target: 10\n",
      "when input is [57, 10] the target: 1\n",
      "when input is [57, 10, 1] the target: 46\n",
      "when input is [57, 10, 1, 46] the target: 60\n",
      "when input is [57, 10, 1, 46, 60] the target: 53\n",
      "when input is [57, 10, 1, 46, 60, 53] the target: 72\n",
      "when input is [57, 10, 1, 46, 60, 53, 72] the target: 1\n",
      "when input is [57, 10, 1, 46, 60, 53, 72, 1] the target: 65\n",
      "when input is [72] the target: 1\n",
      "when input is [72, 1] the target: 72\n",
      "when input is [72, 1, 72] the target: 67\n",
      "when input is [72, 1, 72, 67] the target: 1\n",
      "when input is [72, 1, 72, 67, 1] the target: 65\n",
      "when input is [72, 1, 72, 67, 1, 65] the target: 57\n",
      "when input is [72, 1, 72, 67, 1, 65, 57] the target: 1\n",
      "when input is [72, 1, 72, 67, 1, 65, 57, 1] the target: 53\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "for b in range(batch_size):  # batch dimension\n",
    "    for t in range(block_size):  # time dimension\n",
    "        context = xb[b, : t + 1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 104])\n",
      "tensor(5.3029, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "xw'äŒë91ŒF*LKZ“‐q!ChêYêlR‘wJ?97\"y7lH-zôdœgrPp.'9BKQx_èh7yOOh‐”,[VzfW6bs”ç0.90S.k0écü—ÉpA‐cöfy:lDî'(R\n"
     ]
    }
   ],
   "source": [
    "m = BigramLanguageModel()\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(\n",
    "    decode(\n",
    "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[\n",
    "            0\n",
    "        ].tolist()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for 0 : 5.211520195007324\n",
      "Loss for 1000 : 4.098145961761475\n",
      "Loss for 2000 : 3.318737506866455\n",
      "Loss for 3000 : 2.8467729091644287\n",
      "Loss for 4000 : 2.706305980682373\n",
      "Loss for 5000 : 2.4431138038635254\n",
      "Loss for 6000 : 2.5919318199157715\n",
      "Loss for 7000 : 2.4955062866210938\n",
      "Loss for 8000 : 2.6086950302124023\n",
      "Loss for 9000 : 2.5684008598327637\n",
      "Loss for 9999 : 2.492804527282715\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):  # increase number of steps for good results...\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % 1000 == 0:\n",
    "        print(f\"Loss for {steps} : {loss.item()}\")\n",
    "print(f\"Loss for {steps} : {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kio \"_'\n",
      "Yogg or‐_ thase t ngh, l, onvef a an t The w\n",
      "s hivenouthelfome tist bîud But trkie m;Thalsto\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    decode(\n",
    "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[\n",
    "            0\n",
    "        ].tolist()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"state_dict\": m.state_dict(),\n",
    "    },\n",
    "    \"model_store/fyodor.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4405, -0.2665,  1.5802,  ...,  0.5035, -0.0892,  0.2469],\n",
       "        [ 0.0377, -0.8076,  0.5226,  ..., -0.9246, -0.3201,  0.0784],\n",
       "        [ 1.2510, -0.6916, -0.3453,  ...,  0.6187,  0.8984, -1.0661],\n",
       "        ...,\n",
       "        [ 0.4359,  1.9608,  0.8644,  ...,  0.1105,  1.6918,  1.2047],\n",
       "        [ 0.5749,  0.8414,  0.7786,  ...,  1.2773,  0.9308, -0.8005],\n",
       "        [-1.6228,  2.4729, -0.9491,  ..., -0.0866,  0.0571, -0.1878]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = BigramLanguageModel()\n",
    "nlp.token_embedding_table.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load = torch.load(\"model_store/fyodor.pt\")\n",
    "nlp.load_state_dict(load[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.4199, -1.6624, -5.6457,  ..., -5.1911,  1.6332, -4.8237],\n",
       "        [-4.0091, -1.7476, -6.4224,  ..., -4.5966, -0.7685, -3.9140],\n",
       "        [-0.4226,  2.2950, -3.2307,  ..., -0.5295, -3.9646,  1.0517],\n",
       "        ...,\n",
       "        [-1.2289,  1.1327, -1.8753,  ..., -5.1657, -3.7434, -1.3443],\n",
       "        [-3.4093, -1.8516, -4.1773,  ..., -4.5596, -3.1489, -4.8970],\n",
       "        [ 2.4127,  2.5272, -5.1438,  ..., -5.5503, -3.9697, -3.3135]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.token_embedding_table.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ucond has\n",
      "lvert ce Bly, æ3çYo thourtheceng heron y f oreeramanorthanere out ithlemy totrere omend e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    decode(\n",
    "        nlp.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[\n",
    "            0\n",
    "        ].tolist()\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-HRU81zog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
