{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_files_from_folder, open_txt\n",
    "from src.model import BigramLanguageModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTES FROM THE UNDERGROUND[*]\n",
      "A NOVEL\n",
      "\n",
      "\n",
      "* The author of the diary and the diary itself are, of course,\n",
      "imaginary. Nevertheless it is clear that such persons as the writer of\n",
      "these notes not only may, but positively must, exist in our society,\n",
      "when we consider the circumstances in the midst of which our society is\n",
      "formed. I have tried to expose to the view of the public more\n",
      "distinctly than is commonly done, one of the characters of the recent\n",
      "past. He is one of the representatives of a generatio\n"
     ]
    }
   ],
   "source": [
    "books = get_files_from_folder(\"books\")\n",
    "books_string = [open_txt(f\"books/{i}\") for i in books]\n",
    "print(books_string[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All books have a lenght of: 7113352\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'Æ', 'É', 'à', 'â', 'ä', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ô', 'ö', 'ü', 'Œ', 'œ', '‐', '—', '‘', '’', '“', '”']\n",
      "The vocabulary has a lenght of: 104\n"
     ]
    }
   ],
   "source": [
    "all_books = \"\\n\".join(books_string)\n",
    "print(f\"All books have a lenght of: {len(all_books)}\")\n",
    "\n",
    "vocab = sorted(set(all_books))\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)\n",
    "print(f\"The vocabulary has a lenght of: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 67, 71, 72, 67, 77, 57, 74, 71, 63, 77]\n",
      "Dostoyevsky\n"
     ]
    }
   ],
   "source": [
    "stoi = {c: i for i, c in enumerate(vocab)}\n",
    "itos = {i: c for i, c in enumerate(vocab)}\n",
    "encode = lambda x: [stoi[c] for c in x]\n",
    "decode = lambda x: \"\".join([itos[c] for c in x])\n",
    "\n",
    "print(encode(\"Dostoyevsky\"))\n",
    "print(decode(encode(\"Dostoyevsky\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7113352]) torch.int64\n",
      "tensor([37, 38, 43, 28, 42,  1, 29, 41, 38, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13240/3704913605.py:1: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  data = torch.tensor(encode(all_books), dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(all_books), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.9)\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[  1,  65,  57,   1,  59,  67,  10, 103],\n",
      "        [ 61,  57,  70,  71,   1,  71,  53,  77],\n",
      "        [ 66,  64,  77,   1,  55,  53,  65,  57],\n",
      "        [ 61,  65,  61,  66,  59,  10,   1,  27]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 65,  57,   1,  59,  67,  10, 103,   0],\n",
      "        [ 57,  70,  71,   1,  71,  53,  77,  10],\n",
      "        [ 64,  77,   1,  55,  53,  65,  57,   1],\n",
      "        [ 65,  61,  66,  59,  10,   1,  27,  53]])\n",
      "----\n",
      "when input is [1] the target: 65\n",
      "when input is [1, 65] the target: 57\n",
      "when input is [1, 65, 57] the target: 1\n",
      "when input is [1, 65, 57, 1] the target: 59\n",
      "when input is [1, 65, 57, 1, 59] the target: 67\n",
      "when input is [1, 65, 57, 1, 59, 67] the target: 10\n",
      "when input is [1, 65, 57, 1, 59, 67, 10] the target: 103\n",
      "when input is [1, 65, 57, 1, 59, 67, 10, 103] the target: 0\n",
      "when input is [61] the target: 57\n",
      "when input is [61, 57] the target: 70\n",
      "when input is [61, 57, 70] the target: 71\n",
      "when input is [61, 57, 70, 71] the target: 1\n",
      "when input is [61, 57, 70, 71, 1] the target: 71\n",
      "when input is [61, 57, 70, 71, 1, 71] the target: 53\n",
      "when input is [61, 57, 70, 71, 1, 71, 53] the target: 77\n",
      "when input is [61, 57, 70, 71, 1, 71, 53, 77] the target: 10\n",
      "when input is [66] the target: 64\n",
      "when input is [66, 64] the target: 77\n",
      "when input is [66, 64, 77] the target: 1\n",
      "when input is [66, 64, 77, 1] the target: 55\n",
      "when input is [66, 64, 77, 1, 55] the target: 53\n",
      "when input is [66, 64, 77, 1, 55, 53] the target: 65\n",
      "when input is [66, 64, 77, 1, 55, 53, 65] the target: 57\n",
      "when input is [66, 64, 77, 1, 55, 53, 65, 57] the target: 1\n",
      "when input is [61] the target: 65\n",
      "when input is [61, 65] the target: 61\n",
      "when input is [61, 65, 61] the target: 66\n",
      "when input is [61, 65, 61, 66] the target: 59\n",
      "when input is [61, 65, 61, 66, 59] the target: 10\n",
      "when input is [61, 65, 61, 66, 59, 10] the target: 1\n",
      "when input is [61, 65, 61, 66, 59, 10, 1] the target: 27\n",
      "when input is [61, 65, 61, 66, 59, 10, 1, 27] the target: 53\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "for b in range(batch_size):  # batch dimension\n",
    "    for t in range(block_size):  # time dimension\n",
    "        context = xb[b, : t + 1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 104])\n",
      "tensor(5.3548, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "G”‘éT Oâ*l”i“J5[PYX'ôK8q(6SBPuA)”UFœæI)î26X—î0ZKpaL]UF.ïï:’,\"AzBVdöOHl\n",
      "vkbiXNw_QHI8pQc”ë5csXKV”Gä —”\n"
     ]
    }
   ],
   "source": [
    "m = BigramLanguageModel()\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(\n",
    "    decode(\n",
    "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[\n",
    "            0\n",
    "        ].tolist()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for 0 : 5.358506679534912\n",
      "Loss for 1000 : 4.173586845397949\n",
      "Loss for 2000 : 3.422147512435913\n",
      "Loss for 3000 : 2.9323503971099854\n",
      "Loss for 4000 : 2.7229998111724854\n",
      "Loss for 5000 : 2.5551624298095703\n",
      "Loss for 6000 : 2.4903650283813477\n",
      "Loss for 7000 : 2.6020524501800537\n",
      "Loss for 8000 : 2.4912445545196533\n",
      "Loss for 9000 : 2.521933078765869\n",
      "Loss for 9999 : 2.5369133949279785\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):  # increase number of steps for good results...\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % 1000 == 0:\n",
    "        print(f\"Loss for {steps} : {loss.item()}\")\n",
    "print(f\"Loss for {steps} : {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "besenif rnZâŒ, ind ainïPheme ma bleay weld, As the orin bybooie r teemid _C39stherchre s, onbllyove \n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    decode(\n",
    "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[\n",
    "            0\n",
    "        ].tolist()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"state_dict\": m.state_dict(),\n",
    "    },\n",
    "    \"model_store/fyodor.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2936, -0.1864,  1.3101,  ..., -0.1238,  1.3173, -1.5328],\n",
       "        [ 0.1537, -0.3418,  0.2981,  ..., -0.3151,  1.1897, -0.5324],\n",
       "        [ 1.2973,  1.6508, -0.1868,  ...,  1.7682,  0.5678,  0.7637],\n",
       "        ...,\n",
       "        [-0.6019,  0.0391, -0.1982,  ...,  0.1669,  0.0601,  0.0303],\n",
       "        [-0.9081,  1.4839,  1.3801,  ..., -0.7037,  0.1223,  1.0521],\n",
       "        [-0.8782, -0.2263, -0.8543,  ...,  0.2864, -1.9203,  0.5960]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = BigramLanguageModel()\n",
    "nlp.token_embedding_table.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load = torch.load(\"model_store/fyodor.pt\")\n",
    "nlp.load_state_dict(load[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.5532, -1.2180, -5.8325,  ..., -2.2854,  1.7837, -3.5798],\n",
       "        [-4.3733, -1.7908, -4.5328,  ..., -5.0469, -0.8697, -4.1664],\n",
       "        [-0.3309,  1.7659, -4.6978,  ..., -0.9283, -3.4268,  1.7296],\n",
       "        ...,\n",
       "        [-0.8234,  1.0634, -2.4750,  ..., -5.0643, -4.4327, -2.3750],\n",
       "        [-4.0360, -1.3939, -5.0085,  ..., -2.4442, -4.0667, -3.8627],\n",
       "        [ 2.5001,  2.5350, -4.8955,  ..., -4.9714, -4.4735, -5.6828]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.token_embedding_table.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a athof w\n",
      "\n",
      "hemeneo t ime\n",
      "atotermursid\n",
      "n or tilas; lis donoour. has Be g hohole I me asy waneridrâlin\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    decode(\n",
    "        nlp.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[\n",
    "            0\n",
    "        ].tolist()\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-HRU81zog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
