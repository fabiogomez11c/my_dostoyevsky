{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "wei = q @ k.transpose(-2, -1)  # (B, T, 16) @ (B, 16, T) = (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "out.shape  # (4, 8, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = key(x)\n",
    "q = query(x)\n",
    "wei = q @ k.transpose(-2, -1)  # (B, T, 16) @ (B, 16, T) = (B, T, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3071, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3514, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5710, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = key(x)\n",
    "q = query(x)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3514, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0982, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1080,  0.2272, -0.0115, -0.3524, -0.1320,  0.0708,  0.0865,  0.1894],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_loss: 2.4255 | val_loss: 2.3884: 100%|██████████| 10000/10000 [00:58<00:00, 169.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from data import FyodorDataset\n",
    "from model import BigramLanguageModel\n",
    "from train import get_batch\n",
    "from utils import get_files_from_folder, open_txt\n",
    "from tqdm import trange\n",
    "\n",
    "batch_size = 128\n",
    "block_size = 32\n",
    "max_iters = 10000\n",
    "eval_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_embd = 32\n",
    "\n",
    "books = get_files_from_folder(\"../books\")\n",
    "books_string = [open_txt(f\"../books/{i}\") for i in books]\n",
    "books = \"\\n\".join(books_string)\n",
    "\n",
    "train_dataset = FyodorDataset(books[: int(len(books) * 0.8)])\n",
    "val_dataset = FyodorDataset(books[int(len(books) * 0.8) :])\n",
    "\n",
    "model = BigramLanguageModel(n_embd=n_embd, block_size=block_size, device=device)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loss = float(\"inf\")\n",
    "val_loss = float(\"inf\")\n",
    "t = trange(max_iters)\n",
    "for steps in t:\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(\n",
    "        train_dataset.data, block_size=block_size, batch_size=batch_size, device=device\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % eval_interval == 0:\n",
    "        train_loss = loss.item()\n",
    "        # evalute on valditation set\n",
    "        model.eval()\n",
    "        val_loss = torch.zeros(eval_iters)\n",
    "        with torch.no_grad():\n",
    "            for i in range(eval_iters):\n",
    "                xb, yb = get_batch(\n",
    "                    val_dataset.data,\n",
    "                    block_size=block_size,\n",
    "                    batch_size=512,\n",
    "                    device=device,\n",
    "                )\n",
    "                logits, loss = model(xb, yb)\n",
    "                val_loss[i] = loss\n",
    "            val_loss = val_loss.mean()\n",
    "\n",
    "        t.set_description(f\"train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tooitlat hot nishe sa shapti.\n",
      "Thore I welitm my\n",
      "wite duritnly\n",
      "ther Loixpicedfusevastolly gqeirus, dimocud hald ar. \"Arr edyout to spo wito Vad_\n",
      "dry se mens.\n",
      "\n",
      "“\"Itlld fd ito, win mbarn, thady; tooutllls ad\n",
      "of wimy ige erm ori. Lben hitou term tche tove, hars ils, sSter antios toesa’sin hely Roust ld toh wimed itou gh ut tethery simedingth tch wn noffu st to that to Sthe abid\n",
      "ast wtis its skist brlow poporke hanraploke scof he, _I'\n",
      "Co to tha yt aye In sta gh onle yond oron so dll sowusinger the, alu nsmou we irof omy, Lobla ours setnol, on ouine matzediondeles, hanid aboutt immeldere Tro cerapr of aride ye—f ase erekeer! \"ly dis Dom. I ks iroun a, yon tiong heave at—ille, serw..\n",
      ".. “On ow gay dsre ellitle fo righing,\n",
      "\n",
      "annst ourderd\n",
      "thingh wofu heattho No ug hgt he re velff..\n",
      "\n",
      "\n",
      "\n",
      "“Miay a cat rshistthim bieleled‐mie ind ow thy.. Embe he drut the. “Rove of whotors led ckesw\n",
      "timongat ay yofor anndiad her, ne fis ‘st we alyisasce ies whe ared dw ove, acly\n",
      "thoulve sclo dit in. Whe saltitololere\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((1, 1), dtype=torch.long)\n",
    "x = x.to(device)\n",
    "print(model.decode(model.generate(idx=x, max_new_tokens=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-HRU81zog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
